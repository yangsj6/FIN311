{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# L16: Text Analysis(Part II)\n",
    "[1. Quantifying Text Complexity](#1.-Quantifying-Text-Complexity)\\\n",
    "[2. Sentence Structure and Classification](#2.-Sentence-Structure-and-Classification)\\\n",
    "[3. Measuring Text Similarity](#3.-Measuring-Text-Similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Quantifying Text Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Text Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `count_words` function that calculates word count for an input text. \\\n",
    "In the following code, function `identify_words` uses a regular expression to find and output all words in a given text. Function count_words first applies `identify_words` to a given text to get a list of all words from that text(stored in variable `words`). It then outputs the length of that list, which is equivalent to the total number of words in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def identify_words(input_text :str):\n",
    "    \"\"\" Extracts all words from a given text. \"\"\"\n",
    "    words = re.findall(r\"\\b[a-zA-Z\\'\\-]+\\b\", input_text)\n",
    "    return words\n",
    "def count_words(input_text : str):\n",
    "    \"\"\" Counts the number of words in a given text. \"\"\"\n",
    "    words = identify_words(input_text)\n",
    "    # calculates the number of words in a given text\n",
    "    word_count = len(words)\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying `count_words` to a short text would yield:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in text : 143\n"
     ]
    }
   ],
   "source": [
    "# excerpt from Microsoft Corporation's 2016 10-K.\n",
    "text = \"\"\" We acquire other companies and intangible\n",
    "assets and may not realize all the economic benefit\n",
    "from those acquisitions , which could cause an\n",
    "impairment of goodwill or intangibles . We review\n",
    "our amortizable intangible assets for impairment\n",
    "when events or changes in circumstances indicate\n",
    "the carrying value may not be recoverable . We test\n",
    "goodwill for impairment at least annually . Factors\n",
    "that may be a change in circumstances , indicating\n",
    "that the carrying value of our goodwill or\n",
    "amortizable intangible assets may not be\n",
    "recoverable , include a decline in our stock price\n",
    "and market capitalization , reduced future cash flow\n",
    "estimates , and slower growth rates in industry\n",
    "segments in which we participate . We may be\n",
    "required to record a significant charge on our\n",
    "consolidated financial statements during the period\n",
    "in which any impairment of our goodwill or\n",
    "amortizable intangible assets is determined ,\n",
    "negatively affecting our results of operations .\"\"\"\n",
    "text_length = count_words(text)\n",
    "print(f\"Number of words in text : {text_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar manner, we can write a function that counts the number of sentences in an input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in text: 5\n"
     ]
    }
   ],
   "source": [
    "def identify_sentences(input_text:str):\n",
    "    \"\"\" Extracts all sentences from a given text. \"\"\"\n",
    "    sentences = re.findall(r\"\\b[A-Z](?:[^\\.!?]|\\.\\d)*[\\.!?]\", input_text)\n",
    "    return sentences\n",
    "\n",
    "def count_sentences(input_text:str) :\n",
    "    \"\"\" Counts the number of sentences in input_text. \"\"\"\n",
    "    sentences = identify_sentences(input_text)\n",
    "    sentence_count = len(sentences)\n",
    "    return sentence_count\n",
    "\n",
    "num_sentences = count_sentences(text)\n",
    "print(f\"Number of sentences in text: {num_sentences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Text Readability Using the Fog Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `count_syllables` that counts the number of syllables in a given word, and a function `is_complex_word` that for a given word returns True if the word has more than three syllables in it, and False otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# regex pattern that matches vowels in a word\n",
    "# (case-insensitive); used for syllable count\n",
    "re_syllables = re.compile(r'(^|[^aeuoiy])(?!e$)[aeouiy]', re.IGNORECASE)\n",
    "def count_syllables(word:str):\n",
    "    \"\"\" Counts the number of syllables in a word. \"\"\"\n",
    "    # gets all syllable regex pattern matches\n",
    "    # in the input word\n",
    "    syllables_matches = re_syllables.findall(word)\n",
    "    return len(syllables_matches)\n",
    "def is_complex_word(word:str):\n",
    "    \"\"\" Checks whether word has three or more syllables. \"\"\"\n",
    "    return count_syllables(word)>= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following example with `count_syllables` and `is_complex_word` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of syllables in word \"Text\": 1\n",
      "Is word \"Text\" complex? False\n",
      "Number of syllables in word \"analysis\": 4\n",
      "Is word \"analysis\" complex? True\n",
      "Number of syllables in word \"procedure\": 3\n",
      "Is word \"procedure\" complex? True\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of syllables in word \\\"Text\\\":\", count_syllables(\"Text\"))\n",
    "print(\"Is word \\\"Text\\\" complex?\", is_complex_word(\"Text\"))\n",
    "print(\"Number of syllables in word \\\"analysis\\\":\", count_syllables(\"analysis\"))\n",
    "print(\"Is word \\\"analysis\\\" complex?\", is_complex_word(\" analysis \"))\n",
    "print(\"Number of syllables in word \\\"procedure\\\":\", count_syllables(\"procedure\"))\n",
    "print(\"Is word \\\"procedure\\\" complex?\", is_complex_word(\"procedure\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that computes the fog index score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_fog(text:str):\n",
    "    \"\"\" Calculates the fog index for a given text. \"\"\"\n",
    "    # extracts all sentences from the input text\n",
    "    sentences = identify_sentences(text)\n",
    "    # extracts all words from the input text\n",
    "    words = identify_words(text)\n",
    "    # creates a list of complex words by using\n",
    "    # is_complex_word function as a filter\n",
    "    complex_words = list(filter(is_complex_word, words))\n",
    "    # calculates and returns the fog index\n",
    "    return 0.4*(float(len(words)) / float(len(sentences)) + 100*float(len(complex_words)) / float(len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fog index score is 21.78965034965035\n"
     ]
    }
   ],
   "source": [
    "fog_score = calculate_fog(text)\n",
    "print (\"The fog index score is\", fog_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Python Packages to Calculate the Fog Index\n",
    "* pip install py-readability-metrics\n",
    "* python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 21.78965034965035, grade_level: 'college_graduate'\n"
     ]
    }
   ],
   "source": [
    "# Readability class provides methods to compute various\n",
    "# readability metrics\n",
    "from readability import Readability\n",
    "\n",
    "# create a new Readability object with the example text\n",
    "# as an input\n",
    "r = Readability(text)\n",
    "\n",
    "# calculate and output the fog index\n",
    "fog_score = r.gunning_fog()\n",
    "print(fog_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9Tnd8cwpKzz"
   },
   "source": [
    "# 2. Sentence Structure and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying forward-looking sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with generating regular expressions that correspond to future-oriented terms as per Appendix “Identifying\n",
    "Forward-Looking Disclosures” in Muslu et al. (2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[re.compile('\\\\bwill\\\\b'), re.compile('\\\\bfuture\\\\b'), re.compile('\\\\bnext fiscal\\\\b')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# To identify FLS , we need a dictionary file that\n",
    "# includes future - oriented verbs and their\n",
    "# conjugations as well as terms that identify\n",
    "# references to the future . In our case , this\n",
    "# file is \"fls_terms.txt.\"\n",
    "\n",
    "# file path(location)to a text file with FLS\n",
    "# terms(dictionary structure : one term per line)\n",
    "fls_terms_file = r\".\\fls_terms.txt\"\n",
    "\n",
    "# next , create a list of regex expressions that\n",
    "# match FLS terms\n",
    "def create_fls_regex_list(fls_terms_file : str):\n",
    "    \"\"\" Creates a list of regex expressions of FLS terms \"\"\"\n",
    "    \n",
    "    # opens the specified dict_file in \"r\" (read) mode\n",
    "    with open(fls_terms_file ,\"r\") as file:\n",
    "        # reads the content of the file line -by - line\n",
    "        # and creates a list of FLS terms\n",
    "        fls_terms = file.read().splitlines()\n",
    "        \n",
    "    # creates a list of FLS regex expressions by adding\n",
    "    # word boundary (\\b) anchors to the beginning and\n",
    "    # the ending of each FLS term\n",
    "    fls_terms_regex = [re.compile(r'\\b'+term+r'\\b') for term in fls_terms]\n",
    "    return fls_terms_regex\n",
    "\n",
    "# creates a list of FLS regex expressions\n",
    "fls_terms_regex = create_fls_regex_list (fls_terms_file)\n",
    "print(fls_terms_regex[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function that checks if a sentence is forward-looking or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m False \u001b[0m : Finally , we launched a completely new website\n",
      "experience for Atlanta .\n",
      "\u001b[1m False \u001b[0m : The new online experience\n",
      "provides a modern and fresh brand look and includes\n",
      "enhanced simplicity and flexibility for shopping and\n",
      "buying that easily transitions to a home delivery or\n",
      "in - store experience .\n",
      "\u001b[1m False \u001b[0m : We are excited to put the customer\n",
      "in the driver seat .\n",
      "\u001b[1m False \u001b[0m : This experience is a unique and\n",
      "powerful integration of our own in - store and online\n",
      "capabilities .\n",
      "\u001b[1m True \u001b[0m : Keep in mind , we will continue to improve\n",
      "both the customer and associate experience in Atlanta\n",
      "and use these earnings to inform how we roll out into\n",
      "other markets .\n",
      "\u001b[1m True \u001b[0m : As we previously announced , we\n",
      "anticipate having the omni channel experience available\n",
      "to the majority of our customers by February 2020.\n",
      "\u001b[1m True \u001b[0m : To\n",
      "expand omni channel , we anticipate opening additional\n",
      "customer experience centers .\n",
      "\u001b[1m False \u001b[0m : We 're currently in the\n",
      "process of planning the next locations while taking\n",
      "state regulations into consideration .\n"
     ]
    }
   ],
   "source": [
    "def is_forward_looking (sentence:str, year:int):\n",
    "    \"\"\" Returns whether sentence is forward-looking.\"\"\"\n",
    "    # creates a list of regex expression that match up\n",
    "    # to 10 years into the future\n",
    "    future_year_terms =[re.compile(r\"[^$,]\\b\" + str(y) + r\"\\b(?!(%|,\\d|.\\d))\") for y in range(year+1, year+10)]\n",
    "    \n",
    "    # combines FLS regex expressions , i.e. , regular\n",
    "    # expressions for FLS terms and future years\n",
    "    fls_terms_with_future_years = fls_terms_regex + future_year_terms\n",
    "    \n",
    "    for fls_term in fls_terms_with_future_years :\n",
    "        # fls_term . search(sentence)returns a match\n",
    "        # object if there is a match , and \" None \"\n",
    "        # if there is no FLS term match in the\n",
    "        # sentence\n",
    "        if fls_term.search(sentence):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Input text - excerpt from Apple 's Q4 2018\n",
    "# Earnings Conference Call Transcript\n",
    "text = \"\"\" Finally , we launched a completely new website\n",
    "experience for Atlanta . The new online experience\n",
    "provides a modern and fresh brand look and includes\n",
    "enhanced simplicity and flexibility for shopping and\n",
    "buying that easily transitions to a home delivery or\n",
    "in - store experience . We are excited to put the customer\n",
    "in the driver seat . This experience is a unique and\n",
    "powerful integration of our own in - store and online\n",
    "capabilities . Keep in mind , we will continue to improve\n",
    "both the customer and associate experience in Atlanta\n",
    "and use these earnings to inform how we roll out into\n",
    "other markets . As we previously announced , we\n",
    "anticipate having the omni channel experience available\n",
    "to the majority of our customers by February 2020. To\n",
    "expand omni channel , we anticipate opening additional\n",
    "customer experience centers . We 're currently in the\n",
    "process of planning the next locations while taking\n",
    "state regulations into consideration .\"\"\"\n",
    "sentence_regex = re.compile(r\"\\b[A-Z](?:[^\\.!?]|\\.\\d)*[\\.!?]\")\n",
    "                               \n",
    "def identify_sentences(input_text:str) :\n",
    "    sentences = re.findall(sentence_regex, input_text)\n",
    "    return sentences\n",
    "                               \n",
    "sentences = identify_sentences(text)\n",
    "for sentence in sentences:\n",
    "    print(\"\\033[1m\", is_forward_looking(sentence, 2018), \"\\033[0m\", \":\", sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuamdOs5pKz0"
   },
   "source": [
    "### Dictionary Approach to Sentence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Jv6KYhPzpKz0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m *** Earnings-oriented: True \u001b[1m *** Quantitative : True \u001b[0m --- Operating income margins, excluding the\n",
      "restructuring charges, are projected to be in the\n",
      "range of 4.5% to 4.8%, and interest expense and\n",
      "other income are forecasted to be approximately\n",
      "$18 million and $6 million, respectively.\n",
      "\u001b[1m *** Earnings-oriented: True \u001b[1m *** Quantitative : False \u001b[0m --- While\n",
      "operating performance is expected to remain\n",
      "strong, Agribusiness profits are expected to be\n",
      "lower in the third and fourth quarters as pricing\n",
      "for subsequent sales will not match the high level\n",
      "of the June delivery.\n",
      "\u001b[1m *** Earnings-oriented: False \u001b[1m *** Quantitative : True \u001b[0m --- The Company expects its\n",
      "capital expenditures in 2008 to be approximately\n",
      "$300 million, an 8% reduction from 2007 capital\n",
      "expenditures of $326 million.\n",
      "\u001b[1m *** Earnings-oriented: False \u001b[1m *** Quantitative : False \u001b[0m --- During the third\n",
      "quarter, the company made further progress\n",
      "implementing the strategic cost reductions that\n",
      "will support the targeted growth investments\n",
      "announced in July 2005.\n"
     ]
    }
   ],
   "source": [
    "# This code implements is a simplified version of\n",
    "# sentence classification as earnings - oriented or\n",
    "# not and quantitative or not as in Bozanic et\n",
    "# al.(2018)\n",
    "\n",
    "# regex for identifying sentences\n",
    "sentence_regex = re.compile(r\"\\b[A-Z](?:[^\\.!?]|\\.\\d)*[\\.!?]\")\n",
    "\n",
    "def identify_sentences(input_text:str):\n",
    "    \"\"\" Returns all sentences in the input text \"\"\"\n",
    "    sentences = re.findall(sentence_regex, input_text)\n",
    "    return sentences\n",
    "\n",
    "earn_terms = [\"earnings\", \"EPS\", \"income\", \"loss\",\n",
    "              \"losses\", \"profit\", \"profits\"]\n",
    "quant_terms = [\"thousand\", \"thousands\", \"million\",\n",
    "               \"millions\", \"billion\", \"billions\",\n",
    "               \"percent\", \"%\", \"dollar\", \"dollars\", \"$\"]\n",
    "\n",
    "# creates a list of earnings regex expressions\n",
    "earn_terms_regex = [re.compile(r'\\b' + term + r'\\b') for term in earn_terms]\n",
    "\n",
    "# creates a list of regexes for quantitative terms\n",
    "quant_terms_regex = [re.compile(r'\\b' + term + r'\\b') for term in quant_terms]\n",
    "\n",
    "# checks if there is a match for at least one earnings\n",
    "# term in the input sentence\n",
    "def is_earn_oriented(sentence:str) :\n",
    "    \"\"\" Checks whether a sentence is earnings-oriented. \"\"\"\n",
    "    for term in earn_terms_regex:\n",
    "        if term.search(sentence, re.IGNORECASE):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# checks if there is a match for at least one\n",
    "# qualitative term in the input sentence\n",
    "def is_quantitative(sentence : str):\n",
    "    \"\"\" Checks whether a sentence is quantitative in nature. \"\"\"\n",
    "    for term in quant_terms_regex:\n",
    "        if term.search(sentence, re.IGNORECASE):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# input text\n",
    "text = \"\"\"Operating income margins, excluding the\n",
    "restructuring charges, are projected to be in the\n",
    "range of 4.5% to 4.8%, and interest expense and\n",
    "other income are forecasted to be approximately\n",
    "$18 million and $6 million, respectively. While\n",
    "operating performance is expected to remain\n",
    "strong, Agribusiness profits are expected to be\n",
    "lower in the third and fourth quarters as pricing\n",
    "for subsequent sales will not match the high level\n",
    "of the June delivery. The Company expects its\n",
    "capital expenditures in 2008 to be approximately\n",
    "$300 million, an 8% reduction from 2007 capital\n",
    "expenditures of $326 million. During the third\n",
    "quarter, the company made further progress\n",
    "implementing the strategic cost reductions that\n",
    "will support the targeted growth investments\n",
    "announced in July 2005.\"\"\"\n",
    "\n",
    "sentences = identify_sentences(text)\n",
    "\n",
    "# next, we classify each sentence as earnings-\n",
    "# oriented or not, quantitative or not\n",
    "for sentence in sentences:\n",
    "    print(\"\\033[1m\", \"*** Earnings-oriented:\", is_earn_oriented(sentence),\n",
    "           \"\\033[1m\", \"*** Quantitative :\", is_quantitative(sentence),\n",
    "           \"\\033[0m\", \"---\", sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Identifying Sentence Subjects and Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we demonstrate how to extract sentences from text using spacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 : Q1 revenue reached $12.7 billion.\n",
      "Sentence 2 : We are\n",
      "thrilled with the continued growth of Apple Card.\n",
      "\n",
      "Sentence 3 : We experienced some product shortages due to very\n",
      "strong customer demand for both Apple Watch and\n",
      "AirPod during the quarter.\n",
      "Sentence 4 : Apple is looking at\n",
      "buying U.K. startup for $1 billion.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# load spacy 's English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# a sample text\n",
    "text = \"\"\"Q1 revenue reached $12.7 billion. We are\n",
    "thrilled with the continued growth of Apple Card.\n",
    "We experienced some product shortages due to very\n",
    "strong customer demand for both Apple Watch and\n",
    "AirPod during the quarter. Apple is looking at\n",
    "buying U.K. startup for $1 billion.\"\"\"\n",
    "\n",
    "# parses the input text using spacy 's nlp class\n",
    "parsed_text = nlp(text)\n",
    "\n",
    "# gets a list of sentences identified by spacy\n",
    "# property \" sents \" yields identified sentences\n",
    "sentences = list(parsed_text.sents)\n",
    "\n",
    "# recall that function enumerate () when applied\n",
    "# to a list, returns its elements along with their\n",
    "# indexes\n",
    "for num, sentence in enumerate(sentences,1):\n",
    "    print(\"Sentence\", str(num), \":\", sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can apply spacy’s tagging method to identify subjects and objects in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 : [{'Token': 'revenue', 'Dependency': 'nsubj'}]\n",
      "Sentence 2 : [{'Token': 'We', 'Dependency': 'nsubjpass'}]\n",
      "Sentence 3 : [{'Token': 'We', 'Dependency': 'nsubj'}]\n",
      "Sentence 4 : [{'Token': 'Apple', 'Dependency': 'nsubj'}]\n"
     ]
    }
   ],
   "source": [
    "def sentence_subj_obj(sentence) :\n",
    "    \"\"\" Identifies subjects and objects in a sentence \"\"\"\n",
    "    results = []\n",
    "    for token in sentence :\n",
    "        # records the token 's text and its dependency\n",
    "        entry = {\"Token\": token.text, \n",
    "                 \"Dependency\": token.dep_}\n",
    "        results.append(entry)\n",
    "\n",
    "    # spacy parses token dependencies and assigns a\n",
    "    # dependency code for each token ; tokens that are\n",
    "    # either objects or subjects will include \"obj\" or\n",
    "    # \" subj \" in their dependency codes ; for a full list\n",
    "    # of spacy 's dependencies and their codes , visit\n",
    "    # spacy.io\n",
    "    \n",
    "    # creates a new list of tokens and their\n",
    "    # dependencies based on results list by keeping\n",
    "    # only tokens with \"obj\" and \" subj \" dependencies\n",
    "    filtered_results =[entry for entry in results\n",
    "                       if ('obj ' in entry['Dependency'])\n",
    "                       or ('subj' in entry['Dependency'])]\n",
    "    return filtered_results\n",
    "\n",
    "# recall that function enumerate () when applied to a\n",
    "# list , returns its elements along with their indexes\n",
    "for num , sentence in enumerate(sentences,1) :\n",
    "    print (\"Sentence\", str(num), \":\", sentence_subj_obj(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, spacy allows us to easily output and visualize complete sentence structure with all word dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Token': 'Q1', 'Lemma_Token': 'Q1', 'POS': 'PROPN', 'Dependency': 'compound', 'Stop_word': False}, {'Token': 'revenue', 'Lemma_Token': 'revenue', 'POS': 'NOUN', 'Dependency': 'nsubj', 'Stop_word': False}, {'Token': 'reached', 'Lemma_Token': 'reach', 'POS': 'VERB', 'Dependency': 'ROOT', 'Stop_word': False}, {'Token': '$', 'Lemma_Token': '$', 'POS': 'SYM', 'Dependency': 'quantmod', 'Stop_word': False}, {'Token': '12.7', 'Lemma_Token': '12.7', 'POS': 'NUM', 'Dependency': 'compound', 'Stop_word': False}, {'Token': 'billion', 'Lemma_Token': 'billion', 'POS': 'NUM', 'Dependency': 'dobj', 'Stop_word': False}, {'Token': '.', 'Lemma_Token': '.', 'POS': 'PUNCT', 'Dependency': 'punct', 'Stop_word': False}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ff19ba55f3a84b81ad959e9902a8c674-0\" class=\"displacy\" width=\"9150\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Q1</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">revenue</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">reached</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">12.7</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">billion.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">We</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">thrilled</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">continued</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">growth</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">Card.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">PUNCT</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">We</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">experienced</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">some</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">product</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">shortages</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">due</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">very</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">strong</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">customer</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">demand</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5475\">both</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5475\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5650\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5650\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5825\">Watch</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5825\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6000\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6000\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6175\">\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6175\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6350\">AirPod</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6350\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6525\">during</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6525\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6700\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6700\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6875\">quarter.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6875\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7050\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7050\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7400\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7575\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7750\">\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7750\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7925\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8100\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8275\">startup</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8275\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8450\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8625\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8625\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8800\">1</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8975\">billion.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8975\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,352.0 205.0,352.0 205.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-1\" stroke-width=\"2px\" d=\"M245,439.5 C245,352.0 380.0,352.0 380.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,441.5 L237,429.5 253,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-2\" stroke-width=\"2px\" d=\"M595,439.5 C595,264.5 910.0,264.5 910.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-3\" stroke-width=\"2px\" d=\"M770,439.5 C770,352.0 905.0,352.0 905.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,441.5 L762,429.5 778,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-4\" stroke-width=\"2px\" d=\"M420,439.5 C420,177.0 915.0,177.0 915.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,441.5 L923.0,429.5 907.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-5\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,177.0 1615.0,177.0 1615.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,441.5 L1112,429.5 1128,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-6\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,264.5 1610.0,264.5 1610.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,441.5 L1287,429.5 1303,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-7\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,352.0 1430.0,352.0 1430.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1430.0,441.5 L1438.0,429.5 1422.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-8\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,352.0 1780.0,352.0 1780.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1780.0,441.5 L1788.0,429.5 1772.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-9\" stroke-width=\"2px\" d=\"M1995,439.5 C1995,264.5 2310.0,264.5 2310.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,441.5 L1987,429.5 2003,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-10\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,352.0 2305.0,352.0 2305.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2170,441.5 L2162,429.5 2178,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-11\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,177.0 2315.0,177.0 2315.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2315.0,441.5 L2323.0,429.5 2307.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-12\" stroke-width=\"2px\" d=\"M2345,439.5 C2345,352.0 2480.0,352.0 2480.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2480.0,441.5 L2488.0,429.5 2472.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-13\" stroke-width=\"2px\" d=\"M2695,439.5 C2695,352.0 2830.0,352.0 2830.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2695,441.5 L2687,429.5 2703,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-14\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,89.5 2845.0,89.5 2845.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2845.0,441.5 L2853.0,429.5 2837.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-15\" stroke-width=\"2px\" d=\"M2870,439.5 C2870,352.0 3005.0,352.0 3005.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3005.0,441.5 L3013.0,429.5 2997.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-16\" stroke-width=\"2px\" d=\"M3220,439.5 C3220,352.0 3355.0,352.0 3355.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3220,441.5 L3212,429.5 3228,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-17\" stroke-width=\"2px\" d=\"M3570,439.5 C3570,264.5 3885.0,264.5 3885.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3570,441.5 L3562,429.5 3578,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-18\" stroke-width=\"2px\" d=\"M3745,439.5 C3745,352.0 3880.0,352.0 3880.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3745,441.5 L3737,429.5 3753,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-19\" stroke-width=\"2px\" d=\"M3395,439.5 C3395,177.0 3890.0,177.0 3890.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3890.0,441.5 L3898.0,429.5 3882.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-20\" stroke-width=\"2px\" d=\"M3395,439.5 C3395,89.5 4070.0,89.5 4070.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4070.0,441.5 L4078.0,429.5 4062.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-21\" stroke-width=\"2px\" d=\"M4095,439.5 C4095,352.0 4230.0,352.0 4230.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4230.0,441.5 L4238.0,429.5 4222.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-22\" stroke-width=\"2px\" d=\"M4445,439.5 C4445,264.5 4760.0,264.5 4760.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4445,441.5 L4437,429.5 4453,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-23\" stroke-width=\"2px\" d=\"M4445,439.5 C4445,352.0 4580.0,352.0 4580.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4580.0,441.5 L4588.0,429.5 4572.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-24\" stroke-width=\"2px\" d=\"M4795,439.5 C4795,264.5 5110.0,264.5 5110.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4795,441.5 L4787,429.5 4803,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-25\" stroke-width=\"2px\" d=\"M4970,439.5 C4970,352.0 5105.0,352.0 5105.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4970,441.5 L4962,429.5 4978,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-26\" stroke-width=\"2px\" d=\"M4270,439.5 C4270,177.0 5115.0,177.0 5115.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5115.0,441.5 L5123.0,429.5 5107.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-27\" stroke-width=\"2px\" d=\"M5145,439.5 C5145,352.0 5280.0,352.0 5280.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5280.0,441.5 L5288.0,429.5 5272.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-28\" stroke-width=\"2px\" d=\"M5495,439.5 C5495,264.5 5810.0,264.5 5810.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">preconj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5495,441.5 L5487,429.5 5503,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-29\" stroke-width=\"2px\" d=\"M5670,439.5 C5670,352.0 5805.0,352.0 5805.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-29\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5670,441.5 L5662,429.5 5678,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-30\" stroke-width=\"2px\" d=\"M5320,439.5 C5320,177.0 5815.0,177.0 5815.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-30\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5815.0,441.5 L5823.0,429.5 5807.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-31\" stroke-width=\"2px\" d=\"M5845,439.5 C5845,352.0 5980.0,352.0 5980.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-31\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5980.0,441.5 L5988.0,429.5 5972.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-32\" stroke-width=\"2px\" d=\"M6020,439.5 C6020,352.0 6155.0,352.0 6155.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-32\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M6155.0,441.5 L6163.0,429.5 6147.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-33\" stroke-width=\"2px\" d=\"M5845,439.5 C5845,264.5 6335.0,264.5 6335.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-33\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M6335.0,441.5 L6343.0,429.5 6327.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-34\" stroke-width=\"2px\" d=\"M3395,439.5 C3395,2.0 6525.0,2.0 6525.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-34\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M6525.0,441.5 L6533.0,429.5 6517.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-35\" stroke-width=\"2px\" d=\"M6720,439.5 C6720,352.0 6855.0,352.0 6855.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-35\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M6720,441.5 L6712,429.5 6728,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-36\" stroke-width=\"2px\" d=\"M6545,439.5 C6545,264.5 6860.0,264.5 6860.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-36\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M6860.0,441.5 L6868.0,429.5 6852.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-37\" stroke-width=\"2px\" d=\"M7070,439.5 C7070,264.5 7385.0,264.5 7385.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-37\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M7070,441.5 L7062,429.5 7078,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-38\" stroke-width=\"2px\" d=\"M7245,439.5 C7245,352.0 7380.0,352.0 7380.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-38\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M7245,441.5 L7237,429.5 7253,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-39\" stroke-width=\"2px\" d=\"M7420,439.5 C7420,352.0 7555.0,352.0 7555.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-39\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M7555.0,441.5 L7563.0,429.5 7547.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-40\" stroke-width=\"2px\" d=\"M7595,439.5 C7595,352.0 7730.0,352.0 7730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-40\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M7730.0,441.5 L7738.0,429.5 7722.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-41\" stroke-width=\"2px\" d=\"M7595,439.5 C7595,264.5 7910.0,264.5 7910.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-41\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M7910.0,441.5 L7918.0,429.5 7902.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-42\" stroke-width=\"2px\" d=\"M7945,439.5 C7945,352.0 8080.0,352.0 8080.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-42\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M8080.0,441.5 L8088.0,429.5 8072.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-43\" stroke-width=\"2px\" d=\"M7420,439.5 C7420,177.0 8265.0,177.0 8265.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-43\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M8265.0,441.5 L8273.0,429.5 8257.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-44\" stroke-width=\"2px\" d=\"M8295,439.5 C8295,352.0 8430.0,352.0 8430.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-44\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M8430.0,441.5 L8438.0,429.5 8422.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-45\" stroke-width=\"2px\" d=\"M8645,439.5 C8645,264.5 8960.0,264.5 8960.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-45\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M8645,441.5 L8637,429.5 8653,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-46\" stroke-width=\"2px\" d=\"M8820,439.5 C8820,352.0 8955.0,352.0 8955.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-46\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M8820,441.5 L8812,429.5 8828,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ff19ba55f3a84b81ad959e9902a8c674-0-47\" stroke-width=\"2px\" d=\"M8470,439.5 C8470,177.0 8965.0,177.0 8965.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ff19ba55f3a84b81ad959e9902a8c674-0-47\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M8965.0,441.5 L8973.0,429.5 8957.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displacy allows to visualize a sentence structure\n",
    "from spacy import displacy\n",
    "\n",
    "# tags all(word)tokens in an input sentence\n",
    "def sentence_tagging(sentence):\n",
    "    results = []\n",
    "    for token in sentence:\n",
    "        # gets a token, its lemmatized version, POS,\n",
    "        # dependency, and checks whether it is a stop\n",
    "        # word or not\n",
    "        entry = {\"Token\": token.text ,\n",
    "                 \"Lemma_Token\": token.lemma_ ,\n",
    "                 \"POS\": token.pos_ ,\n",
    "                 \"Dependency\": token.dep_ ,\n",
    "                 \"Stop_word\": token.is_stop}\n",
    "        results.append(entry)\n",
    "    return results\n",
    "\n",
    "# applies sentence_tagging to all sentences\n",
    "tagged_sentences = [sentence_tagging(s) for s in sentences]\n",
    "\n",
    "# prints the output for the first sentence\n",
    "print(tagged_sentences[0])\n",
    "\n",
    "# visualizes sentence dependency\n",
    "displacy.render(parsed_text, style =\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Named Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we demonstrate how to identify and extract named entities from text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$12.7 billion  MONEY     Monetary values, including unit.\n",
      "Apple Card     ORG       Companies, agencies, institutions, etc.\n",
      "Apple Watch    ORG       Companies, agencies, institutions, etc.\n",
      "AirPod         ORG       Companies, agencies, institutions, etc.\n",
      "the quarter    DATE      Absolute or relative dates or periods.\n",
      "Apple          ORG       Companies, agencies, institutions, etc.\n",
      "U.K.           GPE       Countries, cities, states.\n",
      "$1 billion     MONEY     Monetary values, including unit.\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary with descriptions for spacy 's\n",
    "# entity type codes ; the list is available on spacy.io\n",
    "entity_type_descriptions = {\n",
    "    'PERSON':'People, including fictional.',\n",
    "    'NORP':' Nationalities or religious or political groups.',\n",
    "    'FAC':'Buildings, airports, highways, bridges, etc.',\n",
    "    'ORG':'Companies, agencies, institutions, etc.',\n",
    "    'GPE':'Countries, cities, states.',\n",
    "    'LOC':'Non -GPE locations, mountain ranges, bodies of water.',\n",
    "    'PRODUCT':'Objects, vehicles, foods, etc. (Not services.)',\n",
    "    'EVENT':'Named hurricanes, battles, wars, sports events, etc.',\n",
    "    'WORK':'OF_ART Titles of books, songs, etc.',\n",
    "    'LAW':'Named documents made into laws.',\n",
    "    'LANGUAGE':'Any named language.',\n",
    "    'DATE':'Absolute or relative dates or periods.',\n",
    "    'TIME':'Times smaller than a day.',\n",
    "    'PERCENT':'Percentage, including \"%\". ',\n",
    "    'MONEY':'Monetary values, including unit.',\n",
    "    'QUANTITY':'Measurements, as of weight or distance.',\n",
    "    'ORDINAL':'\" first \", \" second \", etc.',\n",
    "    'CARDINAL':'Numerals that do not fall under another type.'}\n",
    "\n",
    "# gets a list of all named entities identified\n",
    "# by spacy, and output them\n",
    "# property \"ents\" returns all identified named\n",
    "# entities in the text\n",
    "named_entities = parsed_text.ents\n",
    "\n",
    "for ent in named_entities :\n",
    "    # gets the named entity (ent. text)\n",
    "    entity = ent.text\n",
    "    # gets the named entity type code\n",
    "    # (e.g., PERSON, ORG, etc.)\n",
    "    entity_type = ent.label_\n",
    "    # gets the named entity description from\n",
    "    # entity_type_descriptions dictionary using\n",
    "    # its type code\n",
    "    entity_desc = entity_type_descriptions[entity_type]\n",
    "    print(f'{ entity:<15}{entity_type:<10}{entity_desc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can calculate the specificity measure by dividing the number of named entities by the number of words in text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of named entities: 8\n",
      "Number of words: 52\n",
      "Specificity score: 6.5\n"
     ]
    }
   ],
   "source": [
    "# counts the number of all words\n",
    "# we assume that every token in a sentence is a word\n",
    "# unless it is punctuation.\n",
    "num_words = len([token for token in parsed_text if not token.is_punct])\n",
    "\n",
    "num_entities = len(named_entities)\n",
    "specificity_score = num_words / num_entities\n",
    "\n",
    "print('Number of named entities:', num_entities)\n",
    "print('Number of words:', num_words)\n",
    "print('Specificity score:', specificity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Stanford NLP for part-of-speech and named entity recognition tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Stanza` can be installed using either conda or pip as follows:\n",
    "* conda install -c stanfordnlp stanza\n",
    "* pip install stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before processing text, we need to download a Stanza language module and create a `Pipeline` object. `Pipeline` object specifies the type of processing that will be applied to a given text (e.g., tokenization, lemmatization, dependency parsing, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd04d827aab4433a65351a459a1901e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 16:12:14 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-12-26 16:12:14 INFO: File exists: C:\\Users\\yangs\\stanza_resources\\en\\default.zip\n",
      "2023-12-26 16:12:17 INFO: Finished downloading models and saved to C:\\Users\\yangs\\stanza_resources.\n",
      "2023-12-26 16:12:17 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9071f41fa3436789c1244fbfea815d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 16:12:17 WARNING: Language en package default expects mwt, which has been added\n",
      "2023-12-26 16:12:18 INFO: Loading these models for language: en (English):\n",
      "=========================================\n",
      "| Processor | Package                   |\n",
      "-----------------------------------------\n",
      "| tokenize  | combined                  |\n",
      "| mwt       | combined                  |\n",
      "| pos       | combined_charlm           |\n",
      "| ner       | ontonotes-ww-multi_charlm |\n",
      "=========================================\n",
      "\n",
      "2023-12-26 16:12:18 INFO: Using device: cpu\n",
      "2023-12-26 16:12:18 INFO: Loading: tokenize\n",
      "2023-12-26 16:12:18 INFO: Loading: mwt\n",
      "2023-12-26 16:12:18 INFO: Loading: pos\n",
      "2023-12-26 16:12:18 INFO: Loading: ner\n",
      "2023-12-26 16:12:18 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "# downloads the English module. The size of the\n",
    "# downloaded module is about 400 MB. The module\n",
    "# has to be download only once\n",
    "stanza.download('en')\n",
    "\n",
    "# creates a(text processing)Pipeline object using\n",
    "# the English language module with tokenizer , part\n",
    "# of speech and named entity recognition\n",
    "nlp = stanza.Pipeline(lang = 'en', processors = 'tokenize, pos, ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a `Stanza` document object by providing an input text. `Stanza` will immediately parse the input text using previously specified text processors at this step. We can retrieve parsed sentences and words through document object properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:\n",
      "Q1 revenue reached $...\n",
      "We are\n",
      "thrilled with...\n",
      "We experienced some ...\n",
      "Apple is looking at\n",
      "...\n",
      "\n",
      "Words:\n",
      "Q1\n",
      "revenue\n",
      "reached\n",
      "$\n",
      "12.7\n",
      "billion\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# sample text (same as in the previous example)\n",
    "text = \"\"\" Q1 revenue reached $12.7 billion. We are\n",
    "thrilled with the continued growth of Apple Card.\n",
    "We experienced some product shortages due to very\n",
    "strong customer demand for both Apple Watch and\n",
    "AirPod during the quarter. Apple is looking at\n",
    "buying U.K. startup for $1 billion.\"\"\"\n",
    "\n",
    "# creates Stanza document object\n",
    "doc = nlp(text)\n",
    "\n",
    "# extracts sentences\n",
    "sentences = doc.sentences\n",
    "\n",
    "print('Sentences:')\n",
    "# prints the first 20 characters of each sentence\n",
    "for sentence in sentences :\n",
    "    print(sentence.text[0:20] + '...')\n",
    "\n",
    "print('\\nWords:')\n",
    "# prints all the words in the first sentence\n",
    "for word in sentences[0].words:\n",
    "    print(word.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word, we can output its part-of-speech tag by accessing the value of its `.pos` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We         PRON\n",
      "are        AUX\n",
      "thrilled   VERB\n",
      "with       ADP\n",
      "the        DET\n",
      "continued  VERB\n",
      "growth     NOUN\n",
      "of         ADP\n",
      "Apple      PROPN\n",
      "Card       PROPN\n",
      ".          PUNCT\n"
     ]
    }
   ],
   "source": [
    "# outputs POS information for each word in the second sentence\n",
    "for word in sentences[1].words :\n",
    "    print(f'{word.text:<10} {word.pos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can output all entities identified by `Stanza`’s NER processor for a given text (or individual sentence) by accessing `.ents` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1              ORG\n",
      "$12.7 billion   MONEY\n",
      "Apple Card      ORG\n",
      "Apple Watch     ORG\n",
      "AirPod          ORG\n",
      "the quarter     DATE\n",
      "Apple           ORG\n",
      "U.K.            GPE\n",
      "$1 billion      MONEY\n"
     ]
    }
   ],
   "source": [
    "# outputs all entities identified in the input text\n",
    "for ent in doc.ents:\n",
    "    print (f'{ent.text:<15} {ent.type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Measuring Text Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Similarity Measure for Long Text: Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access NLTK’s word tokenizer and the list of stop words we need to download two NLTK modules as follows (this has to be done only once):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yangs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yangs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# download NLTK's stopwords module\n",
    "nltk.download('stopwords')\n",
    "# downlod NLTK's punkt module\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calculating text similarity, we should exclude these punctuation character tokens as they introduce noise to bag-of-words vectors. Conveniently, Python includes a list of punctuation characters; we only need to add apostrophe to that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~’\n"
     ]
    }
   ],
   "source": [
    "# Python includes a collection of all punctuation\n",
    "# characters\n",
    "from string import punctuation\n",
    "# add apostrophe to the punctuation character list\n",
    "punctuation_w_apostrophe = punctuation + \"’\"\n",
    "# print all characters\n",
    "print(punctuation_w_apostrophe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can write a custom word tokenizer using NTLK’s list of stop words and the Porter stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports word tokenizer from NLTK\n",
    "from nltk import word_tokenize\n",
    "# imports list of stop words from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "# imports Porter Stemmer module from NLTK\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# creates a list of English stop words\n",
    "set_stopwords = set(stopwords.words('english'))\n",
    "# creates a Porter stemmer object\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# creates a custom tokenizer that removes stop words ,\n",
    "# punctuation , and stems the remaining words\n",
    "def custom_tokenizer(text:str) :\n",
    "    # gets all tokens(words)from the lower - cased\n",
    "    # input text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # filters out stop words\n",
    "    no_sw_tokens = [t for t in tokens if t not in set_stopwords]\n",
    "    # filters out punctuation character tokens\n",
    "    no_sw_punct_tokens = [t for t in no_sw_tokens if t not in punctuation_w_apostrophe]\n",
    "    # stems the remaining words\n",
    "    stem_tokens = [stemmer.stem(t) for t in no_sw_punct_tokens]\n",
    "    # returns stemmed tokens(words)\n",
    "    return stem_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us demonstrate how this tokenizer works using text excerpts from business description sections of 10-K filings of three telecommunication companies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['verizon', 'commun', 'inc.', 'verizon', 'compani', 'hold', 'compani', 'act', 'subsidiari', 'one', 'world', 'lead', 'provid', 'commun', 'inform', 'entertain', 'product', 'servic', 'consum', 'busi', 'government', 'agenc']\n",
      "['lead', 'provid', 'commun', 'digit', 'entertain', 'servic', 'unit', 'state', 'world', 'offer', 'servic', 'product', 'consum', 'u.s.', 'mexico', 'latin', 'america', 'busi', 'provid', 'telecommun', 'servic', 'worldwid']\n",
      "['sprint', 'corpor', 'includ', 'consolid', 'subsidiari', 'commun', 'compani', 'offer', 'comprehens', 'rang', 'wireless', 'wirelin', 'commun', 'product', 'servic', 'design', 'meet', 'need', 'individu', 'consum', 'busi', 'govern', 'subscrib', 'resel']\n"
     ]
    }
   ],
   "source": [
    "# excerpt from Verizon Communications Inc. 2018 10 -K\n",
    "doc_verizon = \"\"\"Verizon Communications Inc. (Verizon\n",
    "or the Company) is a holding company that, acting\n",
    "through its subsidiaries, is one of the world’s\n",
    "leading providers of communications, information\n",
    "and entertainment products and services to\n",
    "consumers, businesses and governmental agencies.\"\"\"\n",
    "\n",
    "# excerpt from AT&T Inc. 2018 10 -K\n",
    "doc_att = \"\"\"We are a leading provider of\n",
    "communications and digital entertainment services\n",
    "in the United States and the world. We offer our\n",
    "services and products to consumers in the U.S.,\n",
    "Mexico and Latin America and to businesses and\n",
    "other providers of telecommunications services\n",
    "worldwide.\"\"\"\n",
    "\n",
    "# excerpt from Sprint Corporation 2018 10 -K\n",
    "doc_sprint = \"\"\"Sprint Corporation, including its\n",
    "consolidated subsidiaries, is a communications\n",
    "company offering a comprehensive range of wireless\n",
    "and wireline communications products and services\n",
    "that are designed to meet the needs of individual\n",
    "consumers, businesses, government subscribers and\n",
    "resellers.\"\"\"\n",
    "\n",
    "tokens_verizon = custom_tokenizer(doc_verizon)\n",
    "print(tokens_verizon)\n",
    "\n",
    "tokens_att = custom_tokenizer(doc_att)\n",
    "print(tokens_att)\n",
    "\n",
    "tokens_sprint = custom_tokenizer(doc_sprint)\n",
    "print(tokens_sprint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use Scikit-learn’s CountVectorizer class o convert text documents to bag-of-words vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['act' 'agenc' 'america' 'busi' 'commun' 'compani' 'comprehens' 'consolid'\n",
      " 'consum' 'corpor']\n",
      "[[1 1 0 1 2 2 0 0 1 0]\n",
      " [0 0 1 1 1 0 0 0 1 0]\n",
      " [0 0 0 1 2 1 1 1 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yangs\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer converts text to bag-of-words vectors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# creates a list of three documents; one for each\n",
    "# company\n",
    "documents = [doc_verizon, doc_att, doc_sprint]\n",
    "\n",
    "# creates a CountVectorizer object with the custom\n",
    "# tokenizer\n",
    "count_vectorizer = CountVectorizer(tokenizer=custom_tokenizer)\n",
    "\n",
    "# converts text documents to bag-of-word vectors\n",
    "count_vecs = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# prints first ten bag-of-words features(words)\n",
    "print(count_vectorizer.get_feature_names_out()[:10])\n",
    "\n",
    "# prints first ten bag-of-words elements(counts)for\n",
    "# each vector the output is a matrix where each row\n",
    "# represents a document vector the element(count )\n",
    "# order in each vector corresponds to the order of\n",
    "# the bag-of-word features\n",
    "print(count_vecs.toarray()[:,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating **Cosine Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.44854261 0.40768712]\n",
      " [0.44854261 1.         0.32225169]\n",
      " [0.40768712 0.32225169 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# cosine_similarity calculates cosine similarity\n",
    "# between vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# calculates text cosine similarity and stores results\n",
    "# in a matrix . The matrix stores pairwise similarity\n",
    "# scores for all documents , similarly to a covariance\n",
    "# matrix\n",
    "cosine_sim_matrix = cosine_similarity(count_vecs)\n",
    "\n",
    "# outputs the similarity matrix\n",
    "print(cosine_sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can slightly modify our previous code to create bag-of-words vectors with IDF weights by using `TfidfVectorizer` class instead of `CountVectorizer`. The former class automatically calculates and applies IDF weights for each documents in the list (corpus) of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['act' 'agenc' 'america' 'busi']\n",
      "[[0.22943859 0.22943859 0.         0.13551013]\n",
      " [0.         0.         0.23464902 0.13858749]\n",
      " [0.         0.         0.         0.13365976]]\n"
     ]
    }
   ],
   "source": [
    "# TfidfVectorizer converts text to TF -IDF bag -of - words\n",
    "# vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# creates a TfidfVectorizer object with the custom\n",
    "# tokenizer\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer = custom_tokenizer)\n",
    "\n",
    "# converts text documents to TF -IDF vectors\n",
    "tfidf_vecs = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# prints first four bag -of - words features(words)\n",
    "print(tfidf_vectorizer.get_feature_names_out()[:4])\n",
    "\n",
    "# prints first four bag -of - words TF -IDF counts for each\n",
    "# vector.The output is a matrix where each row\n",
    "# represents a document vector\n",
    "print(tfidf_vecs.toarray()[:,:4]) # prints first four elements of each vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the cosine similarity between TF-IDF vectors, we can use NTLK’s `cosine_similarity` function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.30593809 0.23499515]\n",
      " [0.30593809 1.         0.17890296]\n",
      " [0.23499515 0.17890296 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# computes the cosine similarity matrix for TF -IDF vectors\n",
    "tfidf_cosine_sim_matrix = cosine_similarity(tfidf_vecs)\n",
    "\n",
    "# outputs the similarity matrix\n",
    "print(tfidf_cosine_sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Similarity Measure for Short Text: Levenshtein Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NLTK` library provides a function called `edit_distance` that calculates the Levenshtein distance between two pieces of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# edit_distance computes Levenshtein distance between\n",
    "# two pieces of text\n",
    "from nltk import edit_distance\n",
    "# example : account and accounts\n",
    "print(edit_distance(\"account\",\"accounts\"))\n",
    "# example : account and count\n",
    "print(edit_distance(\"account\",\"count \"))\n",
    "# example : account and access\n",
    "print(edit_distance(\"account\",\"access\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Similarity Measure using the Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# similarity measure based on the Levenshtein distance\n",
    "# greater values indicate more similar text\n",
    "def edit_similarity(t1, t2):\n",
    "    # lowercase the input strings\n",
    "    (t1, t2) = (t1.lower(), t2.lower())\n",
    "    # calculates the Levenshtein distance between the\n",
    "    # input strings\n",
    "    distance = edit_distance(t1, t2)\n",
    "    # calculates length of the longest input string\n",
    "    longest_text_len = max(len(t1),len(t2))\n",
    "    # if both t1 and t2 are empty strings, they are\n",
    "    # identical ; thus return 1 as the output\n",
    "    if longest_text_len == 0:\n",
    "        return 1.0\n",
    "    # else compute the similarity measure as\n",
    "    # 1 -(levenshtein_distance / length of the longest input string)\n",
    "    else:\n",
    "        return(1.0 - float(distance)/float(longest_text_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us demonstrate how to apply this similarity measure on an example. Consider the problem of matching observations based on company names. The name of an S&P 500 firm, Fidelity National Information Services, is recorded in Capital IQ’s Compustat database as “Fidelity National Info Svcs”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein distance: 11\n",
      "Levenshtein similarity score: 0.7105263157894737\n"
     ]
    }
   ],
   "source": [
    "# original company name\n",
    "orig_name = \"Fidelity National Information Services\"\n",
    "# shortened company name\n",
    "comp_name = \"Fidelity National Info Svcs\"\n",
    "\n",
    "# calculates and outputs the Levenshtein distance\n",
    "levenshtein_distance = edit_distance(orig_name, comp_name)\n",
    "print(\"Levenshtein distance:\", levenshtein_distance)\n",
    "\n",
    "# calculates and output the similarity score based on\n",
    "# Levenshtein distance\n",
    "levenshtein_similarity = edit_similarity(orig_name, comp_name)\n",
    "print(\"Levenshtein similarity score:\", levenshtein_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Semantic Similarity using Word2Vec Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data preprocessing steps**: \n",
    "* removing stop words, special characters, numbers, and extra spaces\n",
    "* extracting individual words from the input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yangs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# imports word tokenizer from NLTK\n",
    "import nltk\n",
    "# download NLTK 's stopwords module\n",
    "nltk.download('stopwords')\n",
    "from nltk import word_tokenize\n",
    "# imports list of stop words from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# creates a list of English stop words\n",
    "set_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# path to the input txt file with Apple 's 2018 MD&A\n",
    "input_file = r\"./Apple_MDNA.txt\"\n",
    "\n",
    "# reads file content\n",
    "file_content = open(input_file, \"r\", encoding='utf-8').read()\n",
    "\n",
    "# converts text to lowercase ; removes all special characters, digits and extra spaces\n",
    "processed_content = file_content.lower()\n",
    "processed_content = re.sub(r'[^a-zA-Z]', ' ',processed_content)\n",
    "processed_content = re.sub(r'\\s+', ' ',processed_content)\n",
    "\n",
    "# creates a list of lists of individual words - this is the input format to Word2Vec model\n",
    "processed_content = [processed_content]\n",
    "words = [nltk.word_tokenize(e) for e in processed_content ]\n",
    "\n",
    "# removes stop words from the list of words\n",
    "for i in range (len(words)) :\n",
    "    words [i] = [w for w in words[i] if w not in set_stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `Gensim` library to build our Word2Vec model. `Gensim` can be installed using either `conda` or `pip` as follows:\n",
    "* conda install -c anaconda gensim\n",
    "* pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Apple’s MD&A wording, we can find similar or related words to the word “sales”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('company', 0.9615598320960999),\n",
       " ('tax', 0.9547304511070251),\n",
       " ('may', 0.9459083080291748),\n",
       " ('net', 0.9442216753959656),\n",
       " ('foreign', 0.9435575604438782),\n",
       " ('product', 0.9414733648300171),\n",
       " ('financial', 0.9407042860984802),\n",
       " ('revenue', 0.9382311701774597),\n",
       " ('billion', 0.9371017813682556),\n",
       " ('cash', 0.9360306859016418)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports Word2Vec from Gensim library\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# creates a Word2Vec model , ignoring words that occur \n",
    "# less than two times in the input text\n",
    "word2vec = Word2Vec(words, min_count = 2)\n",
    "\n",
    "# identifies most related / similar words to 'sales'\n",
    "# based on the input text provided\n",
    "related_words = word2vec.wv.most_similar('sales')\n",
    "related_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we used only one textual document to train the Word2Vec model. However, the performance of the model in identifying word clusters and similarities will greatly improve when we increase the training corpus. A popular option for training Word2Vec is the Google News dataset model. It consists of 300-dimensional embeddings for around three million words and phrases (see https://code.google.com/archive/p/word2vec/ for details and to download ‘GoogleNewsvectors-negative300.bin.gz’ file (∼1.5GB)). With the pre-trained model we can access the word vectors and get the similarity scores as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38531393\n",
      "0.59829676\n",
      "[('Accounting', 0.6579887270927429), ('bookkeeping', 0.6002781391143799), ('auditing', 0.5503429174423218), ('Arthur_Andersen_Enron', 0.5320826768875122), ('restatement', 0.5319856405258179), ('accountancy', 0.5315807461738586), ('bookeeping', 0.5051406621932983), ('Generally_Accepted_Accounting_Principles', 0.5034367442131042), ('accouting', 0.5023786425590515), ('Irina_Parkhomenko_spokeswoman', 0.49402597546577454)]\n",
      "bad\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# load embeddings directly from the downloaded file\n",
    "# called \"GoogleNews-vectors-negative300.bin\"\n",
    "model = KeyedVectors.load_word2vec_format(r'C:\\Users\\yangs\\Downloads\\GoogleNews-vectors-negative300.bin', binary = True)\n",
    "\n",
    "# similarity between pairs of words\n",
    "a = model.similarity('confident', 'uncertain')\n",
    "b = model.similarity('recession', 'crisis')\n",
    "# most similar words\n",
    "c = model.most_similar('accounting')\n",
    "# identifies a word that does not belong in the list\n",
    "d = model.doesnt_match(\"good great amazing bad\".split())\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "14_deep_computer_vision_with_cnns.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0401482a18a94f22b95d5321bfa6f414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c08c78c0d484eed9638ad2b757ab584": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2839afc6cb6d4a50b0bdad1fcb7f39d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eefd1a01ef1c46e09ffbd97ad25377cf",
       "IPY_MODEL_d142189db76a4681a22f38ae252e4ebc",
       "IPY_MODEL_d441368305704ab9a3bdbe762ab340a4"
      ],
      "layout": "IPY_MODEL_1c08c78c0d484eed9638ad2b757ab584"
     }
    },
    "54a90429726b4d848358cafae87ad893": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57cbb645792f45adbfab9b29aa708809": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f0660be3bf44dd48fd42cd52a507e32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b681dc2200ad4ee397a46602e8f4f654": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d142189db76a4681a22f38ae252e4ebc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54a90429726b4d848358cafae87ad893",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0401482a18a94f22b95d5321bfa6f414",
      "value": 5
     }
    },
    "d441368305704ab9a3bdbe762ab340a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8ef3c06db574e3f88dc9a8c0bcd22ab",
      "placeholder": "​",
      "style": "IPY_MODEL_8f0660be3bf44dd48fd42cd52a507e32",
      "value": " 5/5 [00:10&lt;00:00,  2.12s/ file]"
     }
    },
    "eefd1a01ef1c46e09ffbd97ad25377cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b681dc2200ad4ee397a46602e8f4f654",
      "placeholder": "​",
      "style": "IPY_MODEL_57cbb645792f45adbfab9b29aa708809",
      "value": "Dl Completed...: 100%"
     }
    },
    "f8ef3c06db574e3f88dc9a8c0bcd22ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
